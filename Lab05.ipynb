{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNa2ATE0F8oWAuwtSl+5tS1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgukhui/cm4709/blob/main/Lab05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CM4709 Computer Vision\n",
        "#Lab 05 Transfer Learning\n",
        "\n",
        "##Aims\n",
        "In this lab, you will learn how to:\n",
        "1. Load image files into memory.\n",
        "1. Pre-process images.\n",
        "1. Use a CNN to classify a medical images.\n",
        "1. Use Transfer Training for classification."
      ],
      "metadata": {
        "id": "Lhiin-hPtT9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Upload Images to GoogleDrive & Mount to Runtime\n",
        "The dataset we use consists of images in sub-folders.\n",
        "As files in a Colab runtime get deleted when the runtime is stopped, it is recommended that you put the dataset into your GoogleDrive.\n",
        "\n",
        "\n",
        "1. Download the ZIP file from the link in Moodle.\n",
        "1. Decompress the ZIP in your local machine before uploadint to GoogleDrive.\n",
        "1. Once you get the folders and files, upload the whole folder structure to your GoogleDrive.\n",
        "\n",
        "\n",
        "Once you mount your GoogleDrive to your Colab runtime, you will see the folders."
      ],
      "metadata": {
        "id": "IxvGwyA8t1wC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#mount GoogleDrive to Colan runtime\n",
        "#\n",
        "#GoogleDrive will be at the path '/content/gdrive/MyDrive'.\n",
        "#\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "PywyQfC8tZDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define Common Parameters\n",
        "\n",
        "Next, we define some parameters."
      ],
      "metadata": {
        "id": "a7SrqHlm8cKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#path to dataset root folder\n",
        "#***You may need to modify this.***\n",
        "#\n",
        "main_path='/content/gdrive/MyDrive/cm4709/Lab05/data'\n",
        "train_folder_path=main_path+'/train'\n",
        "test_folder_path=main_path+'/test'\n",
        "val_folder_path=main_path+'/val'\n",
        "\n",
        "#get class labels from subfolders under training data subset\n",
        "labels = os.listdir(train_folder_path)\n",
        "\n",
        "#image size\n",
        "img_size = 112\n",
        "\n",
        "#batch size in training\n",
        "batch_size = 16\n",
        "\n",
        "#no. of epochs\n",
        "n_epochs = 25\n",
        "\n",
        "#print sub-folder names\n",
        "print('Class labels: ',labels)"
      ],
      "metadata": {
        "id": "ftodtf8puPAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explore Datasets\n",
        "Get the count of instances in different folders."
      ],
      "metadata": {
        "id": "ZoKquZ0X8Om-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print out image counts in train, test, val folders\n",
        "#\n",
        "train_n_path=train_folder_path+'/NORMAL'\n",
        "train_p_path=train_folder_path+'/PNEUMONIA'\n",
        "\n",
        "test_n_path=test_folder_path+'/NORMAL'\n",
        "test_p_path=test_folder_path+'/PNEUMONIA'\n",
        "\n",
        "val_n_path=val_folder_path+'/NORMAL'\n",
        "val_p_path=val_folder_path+'/PNEUMONIA'\n",
        "\n",
        "print('No. of -ve in training: ',len(os.listdir(train_n_path)))\n",
        "print('No. of +ve in training: ',len(os.listdir(train_p_path)))\n",
        "\n",
        "print('No. of -ve in testing: ',len(os.listdir(test_n_path)))\n",
        "print('No. of +ve in testing: ',len(os.listdir(test_p_path)))\n",
        "\n",
        "print('No. of -ve in validation: ',len(os.listdir(val_n_path)))\n",
        "print('No. of +ve in validation: ',len(os.listdir(val_p_path)))\n"
      ],
      "metadata": {
        "id": "Zy_3IqhYvi3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Function to Load Image Files\n",
        "Define some functions sample the files and to load image into memory.\n",
        "As you may want to load a small set for testing, there is a `sample_rate` parameter for you to select how much from the original dataset to load.\n",
        "\n",
        "Note that we only load in the file pathname for selection. An image file is only loaded if it is selected."
      ],
      "metadata": {
        "id": "6kFLjxzhXV5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "#\n",
        "#get random data sample in a folder with label\n",
        "#folder: the main folder that contain the 2 classes of images\n",
        "#labels: the 2 sub-folders under the main folder\n",
        "#sample_rate: 0-1.0\n",
        "#\n",
        "#return a list of tuple (file_path,label) where label is 0/1 for normal/pnemonia\n",
        "#labels: the subfolder names of NORMAL/PNEUMONIA\n",
        "#folder: path to training/validation/testing sub-dataset\n",
        "#rate: sampling rate of 0-1.0\n",
        "#\n",
        "def get_random_files(labels,dir,sample_rate):\n",
        "  #list holding all filename and class label\n",
        "  files_with_label=[]\n",
        "\n",
        "  #go through both class labels of NORMAL/PNEUMONIA\n",
        "  for label in labels:\n",
        "    #append NORMAL or PNEUMONIA to give full path to images\n",
        "    files=os.listdir(os.path.join(dir,label))\n",
        "\n",
        "    #go through all files in folder\n",
        "    for file in files:\n",
        "      #get full pathname of file\n",
        "      file_path=os.path.join(dir,label,file)\n",
        "\n",
        "      #get class label as 0 or 1\n",
        "      #0 is normal, 1 is pneumonia\n",
        "      #\n",
        "      class_num=labels.index(label)\n",
        "\n",
        "      #append tuple to list\n",
        "      files_with_label.append((file_path,class_num))\n",
        "\n",
        "  #shuffle list of file names\n",
        "  random.shuffle(files_with_label)\n",
        "\n",
        "  #the no. of elements to pick from shuffled list\n",
        "  number=int(len(files_with_label)*sample_rate)\n",
        "\n",
        "  #pick out samples\n",
        "  samples=random.sample(files_with_label,number)\n",
        "  return samples\n",
        "\n",
        "#\n",
        "#load random images with label\n",
        "#similar to get_random_data but actually loads in the images\n",
        "#\n",
        "#labels: the subfolders NORMAL/PNUEMONIA\n",
        "#dir: path to training/validation/testing data subset\n",
        "#img_size: a tuple in the format of (x,y) sizes/dimensions\n",
        "#sample_rate: sampling rate in 0~1.0\n",
        "#\n",
        "def get_random_data(labels,dir,img_size,sample_rate):\n",
        "  #\n",
        "  #pick sample as a list of (file path,class label) tuples\n",
        "  files_with_label=get_random_files(labels,dir,sample_rate)\n",
        "\n",
        "  #lists to hold images and labels\n",
        "  x=[]\n",
        "  y=[]\n",
        "\n",
        "  #go through all samples selected\n",
        "  for file_with_label in files_with_label:\n",
        "      try:\n",
        "        #read image file\n",
        "        (file,label)=file_with_label\n",
        "        img=cv2.imread(file)\n",
        "\n",
        "        #resize image\n",
        "        resized_arr=cv2.resize(img,img_size)\n",
        "\n",
        "        #append to both data and class lists\n",
        "        x.append(resized_arr)\n",
        "        y.append(label)\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "  #convert x,y lists to numpy arrays before returning\n",
        "  #also normalise images\n",
        "  return (np.array(x)/255.0,np.array(y))\n"
      ],
      "metadata": {
        "id": "WPVtKr1zwz7F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing the Sampling Functions\n",
        "\n",
        "We will test our get_random_files(...) and get_random_data(...) functions before we proceed. Also check out the results from both functions."
      ],
      "metadata": {
        "id": "pOjQZSRRjvC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#get 5% sample files from testing data\n",
        "#\n",
        "#get 10% sample of testing data, filenames only\n",
        "sample_files=get_random_files(labels,test_folder_path,0.05)\n",
        "print(\"No. of samples:\",len(sample_files))\n",
        "for file in sample_files:\n",
        "  print(file)\n"
      ],
      "metadata": {
        "id": "_5Qv0XvJjzZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#get 1% sample files from testing data\n",
        "#\n",
        "#get 10% sample of testing data, filenames only\n",
        "(data_x,data_y)=get_random_data(labels,test_folder_path,(100,100),0.01)\n",
        "print(\"X shape: \",data_x.shape)\n",
        "print(\"Y shape: \",data_y.shape)\n",
        "print(\"1st image: \",data_x[0])\n",
        "print(\"1st label: \",data_y[0])"
      ],
      "metadata": {
        "id": "YGOhVW_-Fc6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Datasets\n",
        "We can now load our dataset into memory.\n",
        "Because the original validation dataset is quite small, we won't use it.\n",
        "Instead, we will split the training dataset into training and validation subsets."
      ],
      "metadata": {
        "id": "A8Ax4yGBXaTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get the 2 sub-folders under training folder\n",
        "#they are the class labels\n",
        "#The following is executed in the beginning so we don't need to run it again.\n",
        "#It is only repeated here as a reminder.\n",
        "#\n",
        "#labels=os.listdir(train_folder_path)\n",
        "\n",
        "#only load 10% of dataset\n",
        "sample_rate=0.10\n",
        "\n",
        "#load full training set\n",
        "(x_train_full,y_train_full)=get_random_data(labels,train_folder_path,(img_size,img_size),sample_rate)\n",
        "\n",
        "#split full training set into train and validation sets\n",
        "#10% of the full training set will be used for validation.\n",
        "#\n",
        "val_sample_rate=0.1\n",
        "val_size=int(len(x_train_full)*val_sample_rate)\n",
        "x_val=x_train_full[:val_size]   #validation set\n",
        "y_val=y_train_full[:val_size]\n",
        "x_train=x_train_full[val_size:] #training set\n",
        "y_train=y_train_full[val_size:]\n",
        "\n",
        "#load test set\n",
        "(x_test,y_test)=get_random_data(labels,test_folder_path,(img_size,img_size),sample_rate)\n"
      ],
      "metadata": {
        "id": "Gd4CQTy4yIux"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Examine Loaded Datasets\n",
        "Show number of instances in each subset, and the shape of an instance."
      ],
      "metadata": {
        "id": "MDOu-ErJXd8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Dataset sizes')\n",
        "print('=============')\n",
        "print('x_train_full count: ',len(x_train_full))\n",
        "print('y_train_full count: ',len(y_train_full))\n",
        "\n",
        "print('x_train count: ',len(x_train))\n",
        "print('y_train count: ',len(y_train))\n",
        "print('x_val count: ',len(x_val))\n",
        "print('y_val count: ',len(y_val))\n",
        "\n",
        "#testing set\n",
        "print('x_test count: ',len(x_test))\n",
        "print('y_test count: ',len(y_test))\n",
        "\n",
        "print('\\nType & Shape')\n",
        "print('============')\n",
        "print('x_train type: ',type(x_train))\n",
        "print('y_train type: ',type(y_train))\n",
        "print('x_train data shape: ',x_train.shape)\n",
        "print('y_train data shape: ',y_train.shape)\n",
        "print('x_val type: ',type(x_val))\n",
        "print('y_val type: ',type(y_val))\n",
        "print('x_val data shape: ',x_val.shape)\n",
        "print('y_val data shape: ',y_val.shape)\n",
        "print('x_test type: ',type(x_test))\n",
        "print('y_test type: ',type(y_test))\n",
        "print('x_test data shape: ',x_test.shape)\n",
        "print('y_test data shape: ',y_test.shape)\n",
        "\n",
        "print('\\nSamples')\n",
        "print('=======')\n",
        "print('x_train[0]: ',x_train[0])\n",
        "print('y_train[0]: ',y_train[0])\n",
        "#print('testing data shape: ',test_data.shape)"
      ],
      "metadata": {
        "id": "09z_h2GnXUcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Show Class Distribution"
      ],
      "metadata": {
        "id": "tgo7c-1_cuxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class distribution in training dataset."
      ],
      "metadata": {
        "id": "zxMDGVi633bO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "#\n",
        "#a reusable function to show distribution of values in labels\n",
        "#\n",
        "#labels: an array of 0 or 1. 0s is NORMAL. 1 is PNEUMONIA.\n",
        "#\n",
        "def show_histogram(classes):\n",
        "  l=[]  #array to store all class labels\n",
        "\n",
        "  for c in classes:\n",
        "      l.append(labels[c])   #use c as an index into the labels array\n",
        "\n",
        "  #sns.set_style('whitegrid')\n",
        "  sns.countplot(x=l)\n",
        "\n",
        "#\n",
        "#show distribution in training subset classes/labels\n",
        "#\n",
        "show_histogram(y_train)"
      ],
      "metadata": {
        "id": "HrOtYu6PTB04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class distribution in validation dataset."
      ],
      "metadata": {
        "id": "iXy1ARcf3_ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#show distribution of classes/labels in validation subset\n",
        "#\n",
        "show_histogram(y_val)"
      ],
      "metadata": {
        "id": "SfOQhRlmq_4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class validation in testing dataset."
      ],
      "metadata": {
        "id": "MzwuBB3Z4DJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#show distribution of testing subset classes/labels\n",
        "#\n",
        "show_histogram(y_test)"
      ],
      "metadata": {
        "id": "6x5Q6rcDrEYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Show Random Image in Dataset\n",
        "To make sure that the images and labels are correctly loaded into memory, we will show a random image from a chosen dataset, with its label."
      ],
      "metadata": {
        "id": "9Ut3trm0c6Jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#function to randomly show an image in a dataset\n",
        "#\n",
        "#x_data: an array of images\n",
        "#y_data: an array of labels\n",
        "#\n",
        "def show_random_image(x_data,y_data):\n",
        "  plt.figure(figsize=(3,3))\n",
        "\n",
        "  #get a random index within the range of the array\n",
        "  #\n",
        "  index=random.randint(0,len(x_data)-1)\n",
        "\n",
        "  #get image\n",
        "  #\n",
        "  image=x_data[index]\n",
        "\n",
        "  #plot image\n",
        "  plt.imshow(image)\n",
        "\n",
        "  #get label and show it\n",
        "  label=labels[y_data[index]]\n",
        "  plt.title(label)\n",
        "\n",
        "#\n",
        "#show a random image in the testing dataset\n",
        "#\n",
        "show_random_image(x_test,y_test)"
      ],
      "metadata": {
        "id": "7Vt6zTvqK2DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pre-process Images\n",
        "\n",
        "Depending on the image quality, pre-processing the image may improve the classifier's performance.\n",
        "\n",
        "In this example we will enhance the image contrast by using scikit-image library [`exposure.equalize_hist(...)` function](https://scikit-image.org/docs/stable/api/skimage.exposure.html#skimage.exposure.equalize_hist) to perform [histogram equalization](https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_equalize.html).\n",
        "\n",
        "Note: There are many libraries and functions which can do this. You may find a similar function in OpenCV."
      ],
      "metadata": {
        "id": "FiEmrSxbdWJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#apply histogram equalisation\n",
        "\n",
        "from skimage import exposure\n",
        "\n",
        "#\n",
        "#define function to perform histogram equalisation on an image\n",
        "#\n",
        "def histogram_equalise(image):\n",
        "  image_eq=exposure.equalize_hist(image)\n",
        "#  image_eq=cv2.equalizeHist(image)\n",
        "  return image_eq\n",
        "\n",
        "\n",
        "index=random.randint(0,len(x_train)-1)    #take a random image from the training dataset\n",
        "before=x_train[index]             #original image\n",
        "after=histogram_equalise(before)  #processed image\n",
        "#\n",
        "#show both images\n",
        "#\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(before)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(after)"
      ],
      "metadata": {
        "id": "tZocA9uR7bbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Build CNN Model\n",
        "This CNN model is similar to what we did in the previous lab. There are, however, some extra layers added:\n",
        "1. Some [`BatchNormalization` layer](https://keras.io/api/layers/normalization_layers/batch_normalization/) are added. This is often used to speed up the training process and make it more stable.\n",
        "You can read more about [batch normalization here](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338).\n",
        "1. The [`Dropout` layer](https://keras.io/api/layers/regularization_layers/dropout/) is used to prevent overfitting of the model.\n",
        "1. As we are doing binary classification, we have 1 single output neuron, with the Sigmoid activation function."
      ],
      "metadata": {
        "id": "CQapdBiefzcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#from tensorflow.keras import layers\n",
        "#from tensorflow.keras.models import Sequential\n",
        "#from tensorflow.keras.layers import Activation,Dropout,AveragePooling2D,\n",
        "\n",
        "#defined earlier\n",
        "#just as a reminder\n",
        "#\n",
        "#img_size=112\n",
        "\n",
        "# Model setup\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(32, (3,3), strides = 1, padding = 'same', activation = 'relu', input_shape = (img_size, img_size,3)))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPool2D((2,2), strides = 2, padding = 'same'))\n",
        "model.add(keras.layers.Conv2D(64, (3,3), strides = 1, padding = 'same', activation = 'relu', input_shape = (img_size, img_size,3)))\n",
        "model.add(keras.layers.Dropout(0.1))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPool2D((2,2), strides = 2, padding = 'same'))\n",
        "model.add(keras.layers.Conv2D(64, (3,3), strides = 1, padding = 'same', activation = 'relu', input_shape = (img_size, img_size,3)))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPool2D((2,2), strides = 2, padding = 'same'))\n",
        "model.add(keras.layers.Conv2D(128, (3,3), strides = 1, padding = 'same', activation = 'relu', input_shape = (img_size, img_size,3)))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPool2D((2,2), strides = 2, padding = 'same'))\n",
        "model.add(keras.layers.Conv2D(256, (3,3), strides = 1, padding = 'same', activation = 'relu', input_shape = (img_size, img_size,3)))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPool2D((2,2), strides = 2, padding = 'same'))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(units = 128, activation = 'relu'))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "              optimizer = 'rmsprop', loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy']\n",
        "              )\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "as0WcNkR83oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Just Train the Model\n",
        "You can just go ahead and train the model if you wish.\n",
        "The following code is similar to what we used in the last lab.\n",
        "\n",
        "**However, if you want to tweak your training, wait and see the following cells.**"
      ],
      "metadata": {
        "id": "LNqXxqgzObCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train model\n",
        "#\n",
        "history=model.fit(x_train,y_train,epochs=n_epochs,batch_size=batch_size,\n",
        "                  validation_data=(x_val,y_val))"
      ],
      "metadata": {
        "id": "YQaZc8fICcL2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f94db5-a3bd-4b5e-adec-9452a3868d7d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 1.2961e-07 - accuracy: 1.0000 - val_loss: 0.1635 - val_accuracy: 0.9615\n",
            "Epoch 2/25\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 6.7128e-07 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9615\n",
            "Epoch 3/25\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 2.8368e-04 - accuracy: 1.0000 - val_loss: 0.3211 - val_accuracy: 0.9615\n",
            "Epoch 4/25\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 3.9494e-08 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9808\n",
            "Epoch 5/25\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 4.1471e-05 - accuracy: 1.0000 - val_loss: 0.0162 - val_accuracy: 0.9808\n",
            "Epoch 6/25\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 1.3059e-07 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 4.1917e-08 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 8/25\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 7.0601e-06 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9615\n",
            "Epoch 9/25\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 3.6158e-07 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9615\n",
            "Epoch 10/25\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 5.9089e-09 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9615\n",
            "Epoch 11/25\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 1.5337e-07 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9615\n",
            "Epoch 12/25\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 2.9610e-07 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9615\n",
            "Epoch 13/25\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 1.9457e-08 - accuracy: 1.0000 - val_loss: 0.0743 - val_accuracy: 0.9808\n",
            "Epoch 14/25\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 5.1605e-06 - accuracy: 1.0000 - val_loss: 1.2017 - val_accuracy: 0.9231\n",
            "Epoch 15/25\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 1.4031e-05 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 0.9615\n",
            "Epoch 16/25\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 6.0924e-08 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9615\n",
            "Epoch 17/25\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 3.9873e-08 - accuracy: 1.0000 - val_loss: 0.1756 - val_accuracy: 0.9615\n",
            "Epoch 18/25\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 2.0675e-06 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9615\n",
            "Epoch 19/25\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 2.0419e-07 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9808\n",
            "Epoch 20/25\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 7.8707e-09 - accuracy: 1.0000 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 7.3042e-08 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 3.5773e-08 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 1.5911e-06 - accuracy: 1.0000 - val_loss: 8.6309e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 2.2189e-08 - accuracy: 1.0000 - val_loss: 8.2505e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 2.3747e-07 - accuracy: 1.0000 - val_loss: 6.3308e-04 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image Data Generator\n",
        "\n",
        "\n",
        "Keras has a [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) which can perform data augmentation.\n",
        "We are just showing the code here.\n",
        "Read the documentation for more details."
      ],
      "metadata": {
        "id": "6DuYLDCY2oJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "  featurewise_center=False,\n",
        "  samplewise_center=False,\n",
        "  featurewise_std_normalization=False,\n",
        "  samplewise_std_normalization=False,\n",
        "  zca_whitening=False,\n",
        "  rotation_range = 30,\n",
        "  zoom_range = 0.2,\n",
        "  width_shift_range = 0.1,\n",
        "  height_shift_range = 0.1,\n",
        "  horizontal_flip = True,\n",
        "  vertical_flip=False)\n",
        "\n",
        "datagen.fit(x_train)\n"
      ],
      "metadata": {
        "id": "hHT4qcXX2qfD"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cater for Class Imbalance\n",
        "If you notice the distribution of classes in our dataset, there is a significant imbalance.\n",
        "We can tell Keras to \"pay more attention\" to under-represented classes by passing a `class weight`.\n",
        "\n",
        "The weight of each class is calculated by the following formulae:\n",
        "<center>\n",
        "$\n",
        "weight_{0}=\\frac{1}{neg} \\times \\frac{total}{2}\n",
        "$\n",
        "\n",
        "$\n",
        "weight_{1}=\\frac{1}{pos} \\times \\frac{total}{2}\n",
        "$\n",
        "</center>\n",
        "\n",
        "See more information about **class weights** [here](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#calculate_class_weights)\n"
      ],
      "metadata": {
        "id": "hRu2OnwsMykO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#count of negative and positive cases\n",
        "#\n",
        "neg=0\n",
        "pos=0\n",
        "\n",
        "for y in y_train:\n",
        "  if y==0:\n",
        "    neg=neg+1\n",
        "  else:\n",
        "    pos=pos+1\n",
        "\n",
        "#total number of instances\n",
        "total=neg+pos\n",
        "\n",
        "#calculate weights for both classes\n",
        "#\n",
        "weight_for_0 = 1 /neg * (total/2.0)\n",
        "weight_for_1 = 1/pos *(total/2.0)\n",
        "\n",
        "#put weights into a dictionary\n",
        "#\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Class weights: ',class_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrvdsQGwNJrn",
        "outputId": "f4f19f87-3a90-494b-b662-d51206dcb8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights:  {0: 1.93801652892562, 1: 0.6738505747126436}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Learning Rate\n",
        "\n",
        "Sometime a model's training may get stuck. In this case reducing the learning rate usually helps. In Keras, you can add a callback function which reduces the learning rate if the performance metric does not improve after a few \"patient\" epochs. See the [ReduceLROnPlateau reference](https://keras.io/api/callbacks/reduce_lr_on_plateau/)."
      ],
      "metadata": {
        "id": "NVpnyxszPFIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy', patience = 2, verbose = 1, factor = 0.3, min_lr = 0.000001)\n",
        "\n"
      ],
      "metadata": {
        "id": "GQLDDc6UPMiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(datagen.flow(x_train, y_train, batch_size = batch_size),\n",
        "                    epochs = n_epochs, validation_data = datagen.flow(x_val, y_val),\n",
        "                    callbacks = [learning_rate_reduction], class_weight = class_weight)\n",
        "\n"
      ],
      "metadata": {
        "id": "uziJxyl8OGPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Show Training History\n",
        "\n",
        "The following code to show the history is from the last lab."
      ],
      "metadata": {
        "id": "Trye319_rcPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as pyplot\n",
        "\n",
        "#show keys in the history\n",
        "print(history.history.keys())\n",
        "\n",
        "#plot graphs\n",
        "pd.DataFrame(history.history).plot(figsize=(15,8))\n",
        "pyplot.grid(True)\n",
        "pyplot.gca().set_ylim(0,1)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "ACI4BLqMH8ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Show Training Loss & Validation Loss"
      ],
      "metadata": {
        "id": "kZi96OH9rg9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "losses[['loss','val_loss']].plot()"
      ],
      "metadata": {
        "id": "izp7xQqsXz-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Show Training & Validation Accuracy"
      ],
      "metadata": {
        "id": "R__VMGicrsT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "losses[['accuracy','val_accuracy']].plot()"
      ],
      "metadata": {
        "id": "fweTjszSYJQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate Using Testing Set\n",
        "\n",
        "We can now use the testing dataset to evaluate our model."
      ],
      "metadata": {
        "id": "3pZVzBu0r6A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#evaluate model over the whole testing dataset\n",
        "#\n",
        "(loss,accuracy)=model.evaluate(x_test,y_test)  #result is an array\n",
        "#loss=result[0]      #1st value is loss\n",
        "#accuracy=result[1]  #2nd value is accuracy\n",
        "\n",
        "print(\"Loss of the model is - \" ,loss)\n",
        "print(\"Accuracy of the model is - \" ,accuracy*100 , \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "did-8WoNYRG4",
        "outputId": "73c95966-2c2b-4410-9c75-f02a409fdda4"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 12ms/step - loss: 6.9016 - accuracy: 0.7581\n",
            "Loss of the model is -  6.901576042175293\n",
            "Accuracy of the model is -  75.80645084381104 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predict 1 Image"
      ],
      "metadata": {
        "id": "8GEedpvGiRzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras.models import load_model\n",
        "\n",
        "index=random.randint(0,len(x_test)-1) #get a random index in testing subset\n",
        "x_data=x_test[index]  #get image\n",
        "y_data=y_test[index]  #get label\n",
        "\n",
        "oneImage=np.expand_dims(x_data,axis=0)    #add 1 dimension to x\n",
        "predictions=model.predict(oneImage)       #do prediction\n",
        "pred_classes= np.where(predictions>0.5, 1, 0) #convert floating point number to integer\n",
        "pred_label=labels[pred_classes[0][0]]     #get predicted label\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(x_data)\n",
        "real_label=labels[y_data]\n",
        "plt.title(\"Real:\"+real_label+\" Predicted:\"+pred_label)"
      ],
      "metadata": {
        "id": "vbKnJE9cYbi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Precision, Recall, F1-score, and Support\n",
        "\n",
        "We can get other performance metrics of the model."
      ],
      "metadata": {
        "id": "aszn_Ga1SRMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "#\n",
        "#predict over the testing dataset\n",
        "#\n",
        "predictions=model.predict(x_test)\n",
        "pred_labels= np.where(predictions>0.5, 1, 0)\n",
        "\n",
        "#\n",
        "#print report\n",
        "#\n",
        "print(classification_report(y_test, pred_labels, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))"
      ],
      "metadata": {
        "id": "FHkB-nqdYkBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Show Confusion Matrix"
      ],
      "metadata": {
        "id": "i9TsBtUmrz9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix = confusion_matrix(y_test, pred_labels)\n",
        "plt.figure(figsize = (10,10))\n",
        "classes = ['Pneumonia','Normal']\n",
        "labels = ['TN','FP','FN','TP']\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "\n",
        "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
        "\n",
        "group_counts = ['{0:0.0f}'.format(value) for value in\n",
        "                cf_matrix.flatten()]\n",
        "group_percentages = ['{0:.2%}'.format(value) for value in\n",
        "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
        "          zip(group_names,group_counts,group_percentages)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap= \"YlGn\" ,\n",
        "            xticklabels = classes,yticklabels = classes\n",
        "           )"
      ],
      "metadata": {
        "id": "Mi8uaA4oY1e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transfer Learning\n",
        "\n",
        "We can use a pre-trained model to perform classification.\n",
        "In this example, we will use [ResNet152V2](https://keras.io/api/applications/resnet/#resnet152v2-function).\n",
        "You can explore other pre-trained models available in Keras.\n",
        "You can find more information [here](https://keras.io/guides/transfer_learning/).\n",
        "\n",
        "Note:\n",
        "1. We freeze all layers in the pre-trained model.\n",
        "1. We add a customed input layer, and some dense layers for the output."
      ],
      "metadata": {
        "id": "Bz7kpDyvZAXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16 #(if you want to use VG16)\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "base_model = tf.keras.applications.ResNet152V2(\n",
        "    weights='imagenet',\n",
        "    input_shape=(img_size, img_size, 3),\n",
        "    include_top=False)\n",
        "\n",
        "# freeze the layers\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "l4tPSn2WZ2S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to get pre-trained model\n",
        "#\n",
        "def get_pretrained():\n",
        "\n",
        "    #Input shape = [width, height, color channels]\n",
        "    inputs = layers.Input(shape=(img_size,img_size, 3))\n",
        "\n",
        "    x = base_model(inputs)\n",
        "\n",
        "    # Head\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.1)(x)\n",
        "\n",
        "    #Final Layer (Output)\n",
        "    output = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[inputs], outputs=output)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "xN47PVHqZ_si"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Use Pre-trained Model Directly"
      ],
      "metadata": {
        "id": "my2QQAcRsW0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#get pre-trained model\n",
        "#\n",
        "model_pretrained = get_pretrained()\n",
        "\n",
        "#\n",
        "#compile model\n",
        "#\n",
        "model_pretrained.compile(loss='binary_crossentropy'\n",
        "              , optimizer = tf.keras.optimizers.Adam(learning_rate=0.00005), metrics='binary_accuracy')\n",
        "\n",
        "#\n",
        "#model summary\n",
        "#\n",
        "model_pretrained.summary()\n"
      ],
      "metadata": {
        "id": "1PcNrhjWaH7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fit Data into Pre-trained Model\n",
        "\n",
        "While the layers from the pre-trained model are frozen, we still need to train the dense layers."
      ],
      "metadata": {
        "id": "Ib4UA9essiV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "history_tl = model_pretrained.fit(datagen.flow(x_train,y_train, batch_size = batch_size) ,\n",
        "                    epochs = n_epochs , validation_data = datagen.flow(x_val, y_val) ,\n",
        "                    callbacks = [learning_rate_reduction],\n",
        "                    steps_per_epoch = x_train.shape[0]/batch_size,\n",
        "                    class_weight = class_weight\n",
        "                   )\n",
        "\"\"\"\n",
        "\n",
        "history_tl=model_pretrained.fit(x_train,y_train,epochs=n_epochs,batch_size=batch_size,\n",
        "                  validation_data=(x_val,y_val))"
      ],
      "metadata": {
        "id": "tWUlszMwaQSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Showing Training History of Pre-trained Model"
      ],
      "metadata": {
        "id": "hEoofztTs5YW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as pyplot\n",
        "\n",
        "#show keys in the history\n",
        "print(history_tl.history.keys())\n",
        "\n",
        "#plot graphs\n",
        "pd.DataFrame(history_tl.history).plot(figsize=(15,8))\n",
        "pyplot.grid(True)\n",
        "pyplot.gca().set_ylim(0,1)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "wxyOK7uRbIVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate Pre-trained Model"
      ],
      "metadata": {
        "id": "JSS_KE7mypZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(loss,accuracy)=model_pretrained.evaluate(x_test,y_test)\n",
        "print(\"Loss of the model is - \" , loss)\n",
        "print(\"Accuracy of the model is - \" , accuracy*100 , \"%\")"
      ],
      "metadata": {
        "id": "UACODZGUbTE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine-tuning Model\n",
        "\n",
        "In the last example, we freeze all layers in the pre-trained ResNet model and only train the dense layers added by us.\n",
        "\n",
        "To fine-tune the model, we can unfreeze some layers and retrain them specifically for this domain.\n",
        "We usually keep the lower layers frozen as they capture generic patterns/features common in many domains."
      ],
      "metadata": {
        "id": "lPvjys2eyxH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#first set whole model trainable\n",
        "#\n",
        "base_model.trainable = True\n",
        "\n",
        "#then freeze all except the last 10 layers\n",
        "#\n",
        "for layer in base_model.layers[:-10]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "p7yFAZw0y3GK"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Compile Fine-tune Model"
      ],
      "metadata": {
        "id": "igsw1q_qVaH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_pretrained.compile(loss='binary_crossentropy'\n",
        "              , optimizer = tf.keras.optimizers.Adam(learning_rate=0.000002), metrics='binary_accuracy')\n",
        "\n",
        "model_pretrained.summary()"
      ],
      "metadata": {
        "id": "PZVFEcAuzA02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fit Data Again\n",
        "With the last 10 layers in the model made trainable, we will train it again."
      ],
      "metadata": {
        "id": "WUh2xhTZzdbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "history_ft = model_pretrained.fit(datagen.flow(x_train,y_train, batch_size = batch_size) ,\n",
        "                    epochs = n_epochs , validation_data = datagen.flow(x_val, y_val) ,\n",
        "                    callbacks = [learning_rate_reduction],\n",
        "                    steps_per_epoch = x_train.shape[0]/batch_size,\n",
        "                    class_weight = class_weight\n",
        "                   )\n",
        "\n",
        "\"\"\"\n",
        "history_ft=model_pretrained.fit(x_train,y_train,epochs=30,\n",
        "                  validation_data=(x_val,y_val))"
      ],
      "metadata": {
        "id": "j-LYsRNGzmb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Show Training History"
      ],
      "metadata": {
        "id": "7tfytzo6z0Dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as pyplot\n",
        "\n",
        "#show keys in the history\n",
        "print(history.history.keys())\n",
        "\n",
        "#plot graphs\n",
        "pd.DataFrame(history.history).plot(figsize=(15,8))\n",
        "pyplot.grid(True)\n",
        "pyplot.gca().set_ylim(0,1)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "zBBazMYFzy4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluate Fine-tuned Model"
      ],
      "metadata": {
        "id": "tyq_juDez9JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(loss,accuracy)=model_pretrained.evaluate(x_test,y_test)\n",
        "print(\"Loss of the model is - \" , loss)\n",
        "print(\"Accuracy of the model is - \" , accuracy*100 , \"%\")"
      ],
      "metadata": {
        "id": "J3Ze6UfYz8wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#predict over the testing dataset\n",
        "#\n",
        "predictions=model_pretrained.predict(x_test)\n",
        "pred_labels= np.where(predictions>0.5, 1, 0)\n",
        "\n",
        "#\n",
        "#print report\n",
        "#\n",
        "print(classification_report(y_test, pred_labels, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))"
      ],
      "metadata": {
        "id": "Og67EupIlqYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Confusion Matrix of Fine-tuned Model"
      ],
      "metadata": {
        "id": "ktBdGCd505a2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cf_matrix = confusion_matrix(y_test, pred_labels)\n",
        "plt.figure(figsize = (10,10))\n",
        "\n",
        "labels = ['TN','FP','FN','TP']\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "\n",
        "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
        "\n",
        "group_counts = ['{0:0.0f}'.format(value) for value in\n",
        "                cf_matrix.flatten()]\n",
        "group_percentages = ['{0:.2%}'.format(value) for value in\n",
        "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
        "          zip(group_names,group_counts,group_percentages)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap= \"YlGn\",\n",
        "           xticklabels = classes,yticklabels = classes)"
      ],
      "metadata": {
        "id": "1geXoGBY08CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Clean Up\n",
        "If you need to, the following code terminates the kernel and free memory before running new experiments."
      ],
      "metadata": {
        "id": "AhsBf4LAzY5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)\n"
      ],
      "metadata": {
        "id": "-M13Qz4vzJly"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}