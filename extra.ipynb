{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMfTLJQxWaPH"
      },
      "source": [
        "#CM4709 Computer Vision\n",
        "#On-campus Day Extra Lab\n",
        "\n",
        "##Aim\n",
        "1. To load images from a CSV file of engineering drawing symbols.\n",
        "1. Use CNN to classify these symbols."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sbapiZqWyJI"
      },
      "source": [
        "##Uploading File and Mounting GoogleDrive\n",
        "\n",
        "The symbol drawings are in a CSV file.\n",
        "Upload it to a folder in GoogleDrive.\n",
        "Then mount your GoogleDrive in the runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8vbodwaqO0G"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "gdriveMountPoint='/content/gdrive'\n",
        "drive.mount(gdriveMountPoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiIAX2eOmbqu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "from random import randint\n",
        "\n",
        "# imports for array-handling and plotting\n",
        "import matplotlib\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.layers import Input, Dense\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbK_Hc3dXdpu"
      },
      "source": [
        "##Loading the CSV File\n",
        "\n",
        "We can read the CSV file as a dataframe using Pandas.\n",
        "The format of the CSV:\n",
        "1. Each row/line in the CSV file is a data instance.\n",
        "1. Each data instance has 10000 columns, followed by a label/class column. The 10000 columns represent the 100x100 image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLGjppT_ICdt"
      },
      "outputs": [],
      "source": [
        "datasetLocalPath='/cm4709/OnCampusDay/data/Symbols_pixel.csv'\n",
        "datasetFullPath=gdriveMountPoint+'/MyDrive'+datasetLocalPath\n",
        "print(datasetFullPath)\n",
        "\n",
        "df =pd.read_csv(datasetFullPath)\n",
        "\n",
        "#show first 5 rows dataframe\n",
        "#\n",
        "print('===first 5 rows===')\n",
        "print(df.head())\n",
        "\n",
        "#show the columns\n",
        "#\n",
        "print('===columns===')\n",
        "print(df.columns)\n",
        "\n",
        "#show shape of dataframe\n",
        "#\n",
        "print('===shape===')\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZNAQMADXyED"
      },
      "source": [
        "##Generating Header Names\n",
        "\n",
        "This is optional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSuH1SpJMfK6"
      },
      "outputs": [],
      "source": [
        "#get no. of columns\n",
        "#\n",
        "num_cols=df.shape[1]\n",
        "\n",
        "#generate header\n",
        "#\n",
        "rng=range(1,num_cols)\n",
        "new_cols = ['p_' + str(i) for i in rng]\n",
        "new_cols.append('label')\n",
        "print('===new column names===')\n",
        "print(new_cols)\n",
        "\n",
        "#set column labels of dataframe\n",
        "#ensure the length of the new columns list is equal to the length of df's columns\n",
        "df.columns = new_cols[:num_cols]\n",
        "\n",
        "#show first 5 rows\n",
        "print('===first 5 rows===')\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wz8MxdBLIG_N"
      },
      "outputs": [],
      "source": [
        "#no. of columns\n",
        "#\n",
        "n = df.shape[1]\n",
        "\n",
        "#get 'label' column\n",
        "#this will be y\n",
        "#\n",
        "labels=df['label']\n",
        "print('===labels===')\n",
        "print(labels)\n",
        "\n",
        "#get all columns except last one\n",
        "#this will be x\n",
        "#\n",
        "features=df.iloc[:,0:n-1]\n",
        "\n",
        "print('===features===')\n",
        "print(features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDu_rmdWUmLI"
      },
      "outputs": [],
      "source": [
        "#show shape of x\n",
        "#\n",
        "print('x shape: ',features.values.shape)\n",
        "\n",
        "#show shape of y\n",
        "#\n",
        "print('y shape: ',labels.values.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRtnxsjGYXuK"
      },
      "source": [
        "##Show Random Symbols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2K55bHbrflk"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(8, 8, figsize=(8, 8))\n",
        "\n",
        "#get x as an array\n",
        "#\n",
        "fx = features.values\n",
        "print(ax.flat)\n",
        "\n",
        "#show a number of images\n",
        "#\n",
        "for i, axi in enumerate(ax.flat):\n",
        "  #a random index\n",
        "  value = randint(0, df.shape[0]-1)\n",
        "\n",
        "  #get features, shape it into 100x100 and show it\n",
        "  #\n",
        "  axi.imshow(fx[value].reshape(100,100), cmap='gray')\n",
        "  axi.set(xticks=[], yticks=[])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EwGzZv-YgG6"
      },
      "source": [
        "##Show Class Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tm6Fz4xiwyZ6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(15,7))\n",
        "plt.hist(labels,bins=39)\n",
        "plt.title('Symbols Distribution')\n",
        "plt.xlabel('Symbol Class')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70ent-AzxNLn"
      },
      "outputs": [],
      "source": [
        "#show frequency/count of labels\n",
        "#\n",
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cHKP5-WYy5M"
      },
      "source": [
        "##Remove Infrequent Symbols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WYiXtv-xggK"
      },
      "outputs": [],
      "source": [
        "#remove symbols with less than 7 instances\n",
        "#\n",
        "df = df[~df['label'].isin(['Ultrasonic Flow Meter', 'Barred Tee','Temporary Strainer',\n",
        "                     'Control Valve Angle Choke','Line Blindspacer',\n",
        "                     'Vessel','Valve Gate Through Conduit','Deluge','Control Valve'])]\n",
        "\n",
        "print('shape: ',df.values.shape)\n",
        "print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jM2YU6SxxNf"
      },
      "outputs": [],
      "source": [
        "dataset = df.values\n",
        "# split into input (X) and output (y) variables\n",
        "x = dataset[:, :-1]\n",
        "y = dataset[:,-1]\n",
        "print('x shape: ',x.shape)\n",
        "print('y shape',y.shape)\n",
        "print('===Sample===')\n",
        "print(x[0])\n",
        "print(y[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyZHYfwVx_kO"
      },
      "outputs": [],
      "source": [
        "print(f'There are {len(df.label.unique())} Unique Symbol in the dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fz3TqB3ZJOh"
      },
      "source": [
        "##Examine Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQg_ouQPyFgN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# simple functions to check the shapes of all compoents of the dataset (train, test, labels)\n",
        "\n",
        "def data_summary(x_train, y_train, x_test, y_test):\n",
        "  print('Train images shape:', x_train.shape)\n",
        "  print('Train labels shape:', y_train.shape)\n",
        "  print('Test images shape:', x_test.shape)\n",
        "  print('Test labels shape:', y_test.shape)\n",
        "\n",
        "# split the data and check the shapes of results sets\n",
        "# train_test_split(...) returns numpy arrays\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)\n",
        "data_summary(x_train,y_train,x_test,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2NW-JyJZXHJ"
      },
      "source": [
        "##Reshape Data\n",
        "\n",
        "We need to reshape the 1D array into a 2D one for the CNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DfVwAAQyYCk"
      },
      "outputs": [],
      "source": [
        "print('x_train ',x_train.shape)\n",
        "print('y_train ',y_train.shape)\n",
        "print('x_test ',x_test.shape)\n",
        "print('y_test ',y_test.shape)\n",
        "x_train = x_train.reshape(x_train.shape[0], 100,100,1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 100,100,1)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "print('===AFTER RESHAPE===')\n",
        "print('X_train ',x_train.shape)\n",
        "print('y_train ',y_train.shape)\n",
        "print('X-test ',x_test.shape)\n",
        "print('y_test ',y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6hN8yUrZmJv"
      },
      "source": [
        "##Prepare Data for Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NB_sQd95yhY5"
      },
      "outputs": [],
      "source": [
        "# Encode target variables\n",
        "# prepare target\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "y_train_cat = y_train\n",
        "y_test_cat = y_test\n",
        "\n",
        "# prepare target\n",
        "def prepare_targets(y_train, y_test):\n",
        "    le = LabelEncoder()\n",
        "    le.fit(y_train)\n",
        "    y_train_enc = le.transform(y_train)\n",
        "    y_test_enc = le.transform(y_test)\n",
        "    return y_train_enc, y_test_enc\n",
        "\n",
        "y_train, y_test = prepare_targets(y_train,y_test)\n",
        "\n",
        "print('y_train shape: ',y_train.shape)\n",
        "print('y_test shape:',y_test.shape)\n",
        "print('===Sample===')\n",
        "print(y_train[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIIzQHLzaCe9"
      },
      "source": [
        "##Encode Label Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjB-ZKfnysOj"
      },
      "outputs": [],
      "source": [
        "#from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils import np_utils\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "print('y_train shape: ',y_train.shape)\n",
        "print('y_test shape: ',y_test.shape)\n",
        "print('===Sample===')\n",
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWs3jXMpZwRR"
      },
      "source": [
        "##Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpUQt7OByxp3"
      },
      "outputs": [],
      "source": [
        "#shuffle the training dataset (5 times!)\n",
        "for _ in range(5):\n",
        "    indexes = np.random.permutation(len(x_train))\n",
        "\n",
        "x_train = x_train[indexes]\n",
        "y_train = y_train[indexes]\n",
        "\n",
        "# Keep 10% of the training data for validation\n",
        "# cross-validation sets\n",
        "val_perc = 0.10\n",
        "val_count = int(val_perc * len(x_train))\n",
        "\n",
        "# Validation set (val_data)\n",
        "val_data = x_train[:val_count,:]\n",
        "val_labels_cat = y_train[:val_count,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qIif_SPaH24"
      },
      "source": [
        "##Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cv7riGbSy6bI"
      },
      "outputs": [],
      "source": [
        "def build_modelU():\n",
        "  model = tf.keras.Sequential()\n",
        "  # add Convolutional layers\n",
        "  model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same', input_shape=(100, 100, 1)))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "  model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  # Densely connected layers\n",
        "  #model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "  #model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "  #model.add(tf.keras.layers.Dropout(0.1))\n",
        "  # output layer\n",
        "  model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "  # compile with adam optimizer & categorical_crossentropy loss function\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = build_modelU()\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGPHPhfxaMcK"
      },
      "source": [
        "##Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C_EfYuR67nfi"
      },
      "outputs": [],
      "source": [
        "nEpochs = 25\n",
        "results = model.fit(x_train, y_train,\n",
        "                    epochs=nEpochs, batch_size=64,\n",
        "                    validation_data=(val_data, val_labels_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fz64RWKPaQtS"
      },
      "source": [
        "##Plot Training History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s0jkebAw73aX"
      },
      "outputs": [],
      "source": [
        "history_dict = results.history\n",
        "print(history_dict.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjLicvKRaTQK"
      },
      "source": [
        "##Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bHFt3N7777lz"
      },
      "outputs": [],
      "source": [
        "# accuracy, test\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test, batch_size=64)\n",
        "print('Test loss: %.4f accuracy: %.4f' % (test_loss, test_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6OVQqEmd8F6D"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test)\n",
        "preds = np.argmax(predictions, axis=1)\n",
        "actuals = np.argmax(y_test,axis=1)\n",
        "print('Accuracy: ',sum(preds==actuals)/x_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CbL0_5aB8NSz"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuracy:', score[1])\n",
        "predictions = model.predict(x_test)\n",
        "preds = np.argmax(predictions, axis=1)\n",
        "actuals = np.argmax(y_test,axis=1)\n",
        "#print(confusion_matrix(preds,actuals))\n",
        "# correctly identified symbols\n",
        "print('Incorrectly Identified Symbols: ',(np.argmax(predictions, axis=1) != np.argmax(y_test,axis=1)).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6_oDNDC_8WNJ"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print('Train loss:', score[0])\n",
        "print('Train accuracy:', score[1])\n",
        "predictions = model.predict(x_train)\n",
        "preds = np.argmax(predictions, axis=1)\n",
        "actuals = np.argmax(y_train,axis=1)\n",
        "#print(confusion_matrix(preds,actuals))\n",
        "# correctly identified symbols\n",
        "print('Incorrectly Identified Symbols: ',(np.argmax(predictions, axis=1) != np.argmax(y_train,axis=1)).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8K-PuCws8jiP"
      },
      "outputs": [],
      "source": [
        "# Plot the loss and accuracy curves for training and validation\n",
        "sns.set_style('whitegrid')\n",
        "fig, ax = plt.subplots(1,2, figsize=(14, 7))\n",
        "ax[0].plot(results.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[0].plot(results.history['val_loss'], color='r', label=\"validation loss\",axes=ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "ax[1].plot(results.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "ax[1].plot(results.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDm6I7wWai37"
      },
      "source": [
        "##Show Some Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4QJSPA3F8nAJ"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "X_test__ = X_test.reshape(X_test.shape[0], 100, 100)\n",
        "fig, axis = plt.subplots(4, 4, figsize=(8, 12))\n",
        "for i, ax in enumerate(axis.flat):\n",
        "  ax.imshow(X_test__[i], cmap='binary')\n",
        "  ax.set(title = f\"Actual Symbol {y_test[i].argmax()}\\nPredicted is {y_pred[i].argmax()}\");"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5Zhcls/iG6Zeyu+xc6JU/"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}