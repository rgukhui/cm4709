{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrTWiKq/U67978l2tbIt6O"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CM4709 Computer Vision\n",
        "#Lab 06 Object Detection using YOLO\n",
        "\n",
        "##Aims\n",
        "1. Use YOLO for object detection.\n",
        "1. Use YOLO in OpenCV.\n",
        "\n",
        "##Uploading Testing Images\n",
        "We will need some testing images.\n",
        "There are a few in Moodle. You can also add some of your own.\n",
        "Upload them to a folder in your GoogleDrive. e.g. `cm4709/Lab06/data`."
      ],
      "metadata": {
        "id": "2RFdDzWyzWi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mounting GoogleDrive\n",
        "\n",
        "It is faster and easier uploading to GoogleDrive than to a Colab runtime.\n",
        "The following standard code connects your GoogleDrive space to Colab.\n",
        "After this, your image folder should be visible in your Colab runtime."
      ],
      "metadata": {
        "id": "M5t_enwlzwEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "gdriveMountPoint='/content/gdrive'  #mounting point for GoogleDrive\n",
        "drive.mount(gdriveMountPoint)       #mount GoogleDrive"
      ],
      "metadata": {
        "id": "KuoceQ38iJqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Download and Compile Darknet\n",
        "\n",
        "There are a few implementation of YOLO:\n",
        "1. [Darknet](https://pjreddie.com/darknet/): This is the official release and is the fastest.\n",
        "1. [Darkflow](https://github.com/thtrieu/darkflow): This is the Tensorflow version of Darknet.\n",
        "1. [OpenCV](https://opencv-tutorial.readthedocs.io/en/latest/yolo/yolo.html): This is the OpenCV Implementation of YOLO.\n",
        "\n",
        "The following shell commands download Darknet and compile it. After the compilation, you should see a `darknet` folder in your Colab runtime.\n",
        "\n",
        "Note: Every time you connect to a Colab runtime, the files you saved previously are gone. You may need to download and compile Darknet every time. Luckily the process is fast."
      ],
      "metadata": {
        "id": "n2fUFnUXz4kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Path/folder where Darknet will be downloaded.\n",
        "#\n",
        "darknetHome='darknet'\n",
        "\n",
        "!git clone https://github.com/pjreddie/darknet\n",
        "!cd $darknetHome; make"
      ],
      "metadata": {
        "id": "_Uhhy4DtxO-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Get the Pre-trained Weights\n",
        "\n",
        "To do prediction, we also need the weights of a pre-trained YOLO model. We will use a YOLO model trained on the [COCO dataset](https://cocodataset.org/) which contains 80 classes of everyday objects.\n",
        "\n",
        "Assuming that Darknet is downloaded and compiled into the `darknet` folder, we will downlood YOLOv3 weights into the same folder.\n",
        "After running the following shell commands, you should see a file `yolov3.weights` in the `darknet` folder."
      ],
      "metadata": {
        "id": "iWd3Pg_qz2iN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#darknetHome='darknet'  #already defined above\n",
        "\n",
        "! cd $darknetHome; wget https://pjreddie.com/media/files/yolov3.weights"
      ],
      "metadata": {
        "id": "WavaBOUZ1Jkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Our Testing Image\n",
        "\n",
        "The following code uses OpenCV to show our testing image. Feel free to change the filename."
      ],
      "metadata": {
        "id": "KQ0uvfPHH91Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "imageFile='mumbai-traffic.jpg'                    #image file name\n",
        "imageFolder='/cm4709/Lab06/data'                  #image folder within GoogleDrive\n",
        "imagePath=gdriveMountPoint+'/MyDrive'+imageFolder+'/'+imageFile #absolute path to image file\n",
        "print('Image: '+imagePath)\n",
        "\n",
        "#load image file\n",
        "img=cv.imread(imagePath)\n",
        "\n",
        "print('Image shape: ',img.shape)\n",
        "\n",
        "#get image height and width, which we will need later\n",
        "(height,width,channels)=img.shape\n",
        "\n",
        "#show image\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n"
      ],
      "metadata": {
        "id": "fnEK_RKnzDOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Running YOLO/Darknet from Command Line\n",
        "\n",
        "We can now run YOLO on our image using the following shell commands.\n",
        "Change the filename or path if you wish.\n",
        "\n",
        "YOLO will print out the objects detected, with class labels and confidences."
      ],
      "metadata": {
        "id": "bnLZCQ5QIIw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#These variables are defined above.\n",
        "#\n",
        "#imageFile='mumbai-traffic.jpg'                    #image file name\n",
        "#imageFolder='/cm4709/Lab06/data'                  #image folder within GoogleDrive\n",
        "#imagePath=gdriveMountPoint+'/MyDrive'+imageFolder+'/'+imageFile #absolute path to image file\n",
        "#darknetHome='darknet'\n",
        "\n",
        "!cd $darknetHome; ./darknet detect cfg/yolov3.cfg yolov3.weights $imagePath\n"
      ],
      "metadata": {
        "id": "O7IEBU4rzQj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualising the Detection\n",
        "\n",
        "Apart from printing out the result, YOLO also generates a file called `predictions.jpg`.\n",
        "You can see this file using OpenCV.\n"
      ],
      "metadata": {
        "id": "O1EQMpxyJcVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#The follow variable is already defined.\n",
        "#\n",
        "#darknetHome='darknet'\n",
        "\n",
        "#Path to output image file.\n",
        "#\n",
        "outputFile=darknetHome+'/predictions.jpg'\n",
        "\n",
        "#Show output using OpenCV.\n",
        "#\n",
        "outputImg=cv.imread(outputFile)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(cv.cvtColor(outputImg, cv.COLOR_BGR2RGB))\n"
      ],
      "metadata": {
        "id": "T6dHKrVdCraN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Seeing the COCO Classes\n",
        "\n",
        "This version of YOLO is trained with the [COCO dataset](https://cocodataset.org/). COCO class names are in the `darknet/data/coco.names` file.\n",
        "The following code prints out the number of classes and the class labels."
      ],
      "metadata": {
        "id": "iFHKIM-pLXEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes=[]\n",
        "\n",
        "with open('darknet/data/coco.names','r') as f:\n",
        "  classes=[line.strip() for line in f.readlines()]\n",
        "\n",
        "print('No. of classes: ',len(classes))\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "OxVtLvVTMDCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using YOLO in OpenCV\n",
        "\n",
        "YOLO is now supported in the OpenCV Deep Neural Network (DNN) module. Instead of compiling DarkNet, we can simply load YOLO withint OpenCV."
      ],
      "metadata": {
        "id": "GpUSLjpgKATu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "net=cv.dnn.readNet('darknet/yolov3.weights','darknet/cfg/yolov3.cfg')\n",
        "\n",
        "#layer_names=net.getLayerNames()\n",
        "#output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "\n",
        "output_layers=net.getUnconnectedOutLayersNames()\n",
        "print('No. of output layers: ',len(output_layers))\n",
        "\n",
        "#generate random colours for the classes\n",
        "colours = np.random.uniform(0, 255, size=(len(classes), 3))\n"
      ],
      "metadata": {
        "id": "0FVJgHIhhu68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To feed an image into YOLO, we need to load and convert it into a blob.\n",
        "We use the [`cv2.dnn.blobFromImage`](https://docs.opencv.org/3.4/d6/d0f/group__dnn.html#ga29f34df9376379a603acd8df581ac8d7) function to convert an image into a blob.\n",
        "\n",
        "Notes:\n",
        "1. We need to scale each pixel value from `0-255` to `0-1.0`. Thus the scaling factor is `1/255`.\n",
        "1. OpenCV stores images in BGR instead of RGB. When we convert the image into a blob, we need to swap the R and B channels.\n",
        "1. YOLO takes images in 3 sizes: $320 \\times 320$, $416 \\times 416$, and $609 \\times 609$. We are using $416 \\times 416$ here."
      ],
      "metadata": {
        "id": "TcUSa850QJRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#img is the image loaded above.\n",
        "#\n",
        "blob=cv.dnn.blobFromImage(img,1/255.0,(416, 416),swapRB=True,crop=False)\n",
        "print('Blob shape: ',blob.shape)\n",
        "\n",
        "net.setInput(blob)\n",
        "\n",
        "#get a list of detections\n",
        "outs = net.forward(output_layers)\n"
      ],
      "metadata": {
        "id": "n6RgiCJH1BSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Understanding the Detection Output\n",
        "\n",
        "The YOLO we use has 3 outputs layers.\n",
        "Detection outputs are in a tuple of 3 elements.\n",
        "Each layer output $13 \\times 13 \\times 3$ detections.\n",
        "Each detection is a Y vector from a grid cell.\n",
        "\n",
        "Each Y vector has 85 elements:\n",
        "1. Elements 0-3 are bounding box values.\n",
        "1. Element 4 is the box confidence score.\n",
        "1. Elements 5-84 are confidence scores of the 80 classes.\n",
        "\n",
        "The following code examines structure of the detection result."
      ],
      "metadata": {
        "id": "aFR27YrXokHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('No. of layout output: ',len(outs))\n",
        "detections=outs[0]\n",
        "print('No. of detections in 1 layer output: ',len(detections))\n",
        "vector=detections[0]\n",
        "print('Bounding box: ',vector[:4])\n",
        "print('Box confidence: ',vector[4])\n",
        "print('Class confidence scores: ',vector[5:])\n"
      ],
      "metadata": {
        "id": "ThPKQUVcon1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Processing the Detections\n",
        "\n",
        "We can now process the detections and collect information into 3 lists:\n",
        "1. `classes_ids`: A list of class IDs. Each class ID is an index into the `classes` list/array of class names.\n",
        "1. `confidences`: Confidence score in the class detected.\n",
        "1. `boxes`: x,y,w,h, values of bounding boxes.\n",
        "\n",
        "Notes:\n",
        "1. In the code below, we ignore detections whose confidence is 0.5 or below.\n",
        "1. The bounding box x,y seem to be relative to the whole image, not a grid cell. You can see this in the calculation below. This makes sense and is easier to process as we don't need to know which grid cell has detected this."
      ],
      "metadata": {
        "id": "DQ2HkUJGsGek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#variables to hold class IDs, confidences, and bounding boxes\n",
        "#\n",
        "class_ids=[]\n",
        "confidences=[]\n",
        "boxes = []\n",
        "\n",
        "for out in outs:\n",
        "  for detection in out:           #each detection is a Y vector from a grid cell\n",
        "    scores = detection[5:]        #class scores\n",
        "    class_id = np.argmax(scores)  #find index of max score. This is the class ID number.\n",
        "    confidence = scores[class_id] #find confidence score of this class\n",
        "    if confidence > 0.5:          #only accept if confidence>0.5\n",
        "      # Object detected\n",
        "      center_x = int(detection[0] * width)  #calculate box centre x\n",
        "      center_y = int(detection[1] * height) #centre y\n",
        "      w = int(detection[2] * width)   #box width\n",
        "      h = int(detection[3] * height)  #box height\n",
        "      # Rectangle coordinates\n",
        "      x = int(center_x - w / 2)   #box top-left x\n",
        "      y = int(center_y - h / 2)   #top-left y\n",
        "      boxes.append([x, y, w, h])            #add bounding box into list\n",
        "      confidences.append(float(confidence)) #add confidence score into list\n",
        "      class_ids.append(class_id)            #add class id into list\n",
        "\n",
        "print('No. of detections remain: ',len(class_ids))\n",
        "print('\\nClass ID list:')\n",
        "print(class_ids)\n",
        "print('\\nConfidence score list:')\n",
        "print(confidences)\n",
        "print('\\nBounding box list:')\n",
        "print(boxes)"
      ],
      "metadata": {
        "id": "oeETgiTiPqVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Non-max Suppression\n",
        "\n",
        "The list of result still contains redundant/duplicate bounding boxes.\n",
        "We need to perform Non-max Suppression.\n",
        "Luckily this is already implemented in [`cv2.dnn.NMSBoxes(...)`](https://docs.opencv.org/3.4/d6/d0f/group__dnn.html#ga9d118d70a1659af729d01b10233213ee) function.\n",
        "\n",
        "Note: The last parameter is the IoU threshold. A higher value means more overlapping is allowed."
      ],
      "metadata": {
        "id": "yRPLA5ttlGfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#perform non-max suppression\n",
        "#\n",
        "#returns indices of detections to remain\n",
        "#\n",
        "indices=cv.dnn.NMSBoxes(boxes,confidences,0.5,0.5)\n",
        "print('No. of detections after Non-max suppression: ',len(indices))"
      ],
      "metadata": {
        "id": "sg_63AkMSFII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a copy of the image\n",
        "imgCopy=img.copy()\n",
        "\n",
        "font = cv.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "#go through the bounding boxes\n",
        "for i in range(len(boxes)):\n",
        "  if i in indices:            #1 of the boxes remaining\n",
        "    x, y, w, h = boxes[i]     #get bounding box values\n",
        "    label = str(classes[class_ids[i]])  #get class label\n",
        "    colour = colours[i]                 #get colour\n",
        "    cv.rectangle(imgCopy, (x, y), (x + w, y + h), colour, 2)    #draw bounding box\n",
        "    cv.putText(imgCopy, label, (x, y -10), font, 0.5, colour)  #draw class label\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(cv.cvtColor(imgCopy, cv.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "-cMyy2rPiN6o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}