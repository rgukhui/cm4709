{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlM165CoaWU+GWNYz4BbZT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#CM4709 Computer Vision\n",
        "#Lab 03 Neural Network\n",
        "\n",
        "##Aims\n",
        "1. Use the Keras library to build a neural network.\n",
        "1. Train a neural network to classify images in a dataset.\n",
        "\n",
        "##The Keras Library\n",
        "Keras is a Deep Learning API built on top of Tensorflow.\n",
        "It allows users to quickly create, train, and validate Deep Learning models using neural network.\n",
        "You can find the Keras library and its documentation at [https://keras.io/](https://keras.io/).\n",
        "Both Keras and Tensorflow are readily available in Colab.\n",
        "\n",
        "##The Dataset\n",
        "\n",
        "We will use the [fashion MNIST dataset](https://www.kaggle.com/datasets/zalando-research/fashionmnist) to run through the implementation of a neural networks using Keras.\n",
        "This dataset has 70,000 gray scale image. Each of these images is $28 \\times 28$ pixel in size. There are 10 different classes in the dataset.\n",
        "\n",
        "##Loading the Dataset\n",
        "Fortunately, the fashion MNIST data is readily available in Keras. ( Documentation is [here](https://keras.io/api/datasets/fashion_mnist/).)\n",
        "Loading the dataset is the simple task of importing the Keras library and calling a function.\n",
        "\n",
        "The [`load_data()` function](https://keras.io/api/datasets/fashion_mnist/#loaddata-function) returns a tuple in the format:\n",
        "\n",
        "`(x_train,y_train),(x_test,y_test)`\n",
        "\n",
        "where:\n",
        "* `x_train`: are numpy array of grayscale images for training\n",
        "* `y_train`: are the labels of the training dataset\n",
        "* `x_test`: are the images for testing\n",
        "* `y_test`: are the labels for testing\n",
        "\n",
        "Simply speaking, the `x_...` datasets are images.\n",
        "The `y_...` datasets are class labels.\n",
        "Class labels are in the range 0-9. (Reference is [here](https://keras.io/api/datasets/fashion_mnist/).)\n",
        "\n",
        "The following code loads the dataset and prints out some information:"
      ],
      "metadata": {
        "id": "1dKSC_pRqAme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#load dataset from Keras\n",
        "(x_train_full,y_train_full),(x_test,y_test)=keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "print('Full training dataset (images):',x_train_full.shape)\n",
        "print('Full training dataset (labels):',y_train_full.shape)\n",
        "print('Testing dataset (images):',x_test.shape)\n",
        "print('Testing dataset (labels):',y_test.shape)\n"
      ],
      "metadata": {
        "id": "MGbyIS0Y2FXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Questions:\n",
        "1. How do you interpret the \"shape\" of the numpy arrays reported?\n",
        "1. How many instances are there in the training and testing datasets respectively?"
      ],
      "metadata": {
        "id": "X66o9xb-2gU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating a Validation Dataset\n",
        "\n",
        "It is a good habit to create a validation dataset for the purpose of making sure that our model can generalise well over unseen examples.\n",
        "The validation dataset is different from the testing dataset.\n",
        "While a testing dataset is not touched until we evaluate the performance of the model, the validation dataset is used to fine tune hyperparameters of the model, and will be used during the training process.\n",
        "\n",
        "In the following code, we split the full training data into training, and validation datsets:"
      ],
      "metadata": {
        "id": "msOHkjG12zQD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9rfcWk-nVkl"
      },
      "outputs": [],
      "source": [
        "#split full training dataset into validation and training subsets\n",
        "x_valid=x_train_full[:5000]/255.0\n",
        "x_train=x_train_full[5000:]/255.0\n",
        "y_valid=y_train_full[:5000]\n",
        "y_train=y_train_full[5000:]\n",
        "\n",
        "print('Full training dataset (images): ',x_train_full.shape)\n",
        "print('Full training dataset (labels): ',y_train_full.shape)\n",
        "print('    Training dataset (images): ',x_train.shape)\n",
        "print('    Training dataset (labels): ',y_train.shape)\n",
        "print('    Validation dataset (images): ',x_valid.shape)\n",
        "print('    Validation dataset (labels): ',y_valid.shape)\n",
        "print('Testing dataset (images): ',x_test.shape)\n",
        "print('Testing dataset (labels): ',y_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Questions:\n",
        "1. Why do we divide the value of the image arrays by 255.0?"
      ],
      "metadata": {
        "id": "p6lYNFVm6Whw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Class Labels\n",
        "\n",
        "The class labels are in the range 0-9, with each value corresponding to a type of garment.\n",
        "The following code visualises some images from the training dataset and display them with their labels:"
      ],
      "metadata": {
        "id": "jbOF4bv8qgmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#class names in an array\n",
        "class_names=['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
        "\n",
        "#get size of training dataset\n",
        "(instance_count,width,height)=x_train.shape\n",
        "\n",
        "#randomly show 9 images from training dataset\n",
        "for i in range(9):\n",
        "  #get a random index within the training dataset\n",
        "  index=random.randint(0,instance_count-1)\n",
        "\n",
        "  #get image from training dataset\n",
        "  image=x_train[index]\n",
        "  pyplot.subplot(3,3,i+1)\n",
        "  pyplot.imshow(image,cmap='gray')\n",
        "\n",
        "  #get image label from training dataset\n",
        "  pyplot.title(class_names[y_train[index]])"
      ],
      "metadata": {
        "id": "ffazD2u5otEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building the Neural Network\n",
        "\n",
        "The following code builds a neural network of 4 layers.\n",
        "1. We use a [Sequential model](https://keras.io/guides/sequential_model/).\n",
        "1. In the input layer, we will feed a grayscale image of size $28 \\times 28$. We use a [Flatten layer](https://keras.io/api/layers/reshaping_layers/flatten/).\n",
        "1. The 2 hidden layers are [Dense layers](https://keras.io/api/layers/core_layers/dense/).\n",
        "1. The output layer has 10 neurons as there are 10 classes.\n",
        "1. In the output layer, we use the [Softmax activation function](https://keras.io/api/layers/activations/#softmax-function). (Also see [this article](https://towardsdatascience.com/softmax-activation-function-how-it-actually-works-d292d335bd78) on the explanation of Softmax.)"
      ],
      "metadata": {
        "id": "rmO3L5yXqsNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a neural network using Keras\n",
        "model=keras.models.Sequential()\n",
        "\n",
        "#build the first input layer\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28)))\n",
        "\n",
        "#add the next hidden, dense layer with 300 neurons, using ReLU activation function\n",
        "model.add(keras.layers.Dense(300,activation='relu'))\n",
        "\n",
        "#add the next hidden layer with 100 neurons, using ReLU\n",
        "model.add(keras.layers.Dense(100,activation='relu'))\n",
        "\n",
        "#add the output layer with 10 neurons, corresponding to the 10 classes\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))\n",
        "\n",
        "#print a summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "o_S58ieqrCge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Questions\n",
        "Look at the shape and number of parameters in each layer.\n",
        "Every parameter in the model corresponds to a weight.\n",
        "1. How many neurons do we have in the input layer?\n",
        "1. How many weights (i.e. parameters) do we have in the input layer?\n",
        "1. In the 2nd layer (i.e. 1st hidden layer), how many neurons do we have?\n",
        "1. How many weights are there in the 2nd layer (i.e. 1st hidden layer)? How is this number computed/decided?\n"
      ],
      "metadata": {
        "id": "dumXoUT0q0SI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Weights\n",
        "Our network is not trained at the moment.\n",
        "All weights are randomly assigned a value.\n",
        "The following code print out the values of the weights and biases.\n",
        "(Reference of `layers.get_weights()` is [here](https://keras.io/api/layers/base_layer/#getweights-method).)"
      ],
      "metadata": {
        "id": "m5onzFTfz2Hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get weight & baises in the 2nd layer (i.e. 1st hidden layer)\n",
        "(weights,biases)=model.layers[1].get_weights()\n",
        "\n",
        "print('Weights:')\n",
        "print(weights)\n",
        "print('Biases:')\n",
        "print(biases)"
      ],
      "metadata": {
        "id": "D8yaZJDQrgoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Compiling and Training the Model\n",
        "\n",
        "Once the model is built, we need to compile it before training. Compilation essentially configures the model in defining its loss function, optimizer, and metrics used to determine its accuracy.\n",
        "\n",
        "List of methods on `model` can be found [here](https://keras.io/api/models/model_training_apis/), including [`compile(...)`](https://keras.io/api/models/model_training_apis/#compile-method), and [`fit(...)`](https://keras.io/api/models/model_training_apis/#fit-method).\n",
        "\n",
        "Finally, we training the model by giving it the training dataset and run it through a number of epoches."
      ],
      "metadata": {
        "id": "Gvm18-7hq80F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#train model\n",
        "history=model.fit(x_train,y_train,epochs=30,\n",
        "                  validation_data=(x_valid,y_valid))"
      ],
      "metadata": {
        "id": "TK7qov0vr5zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualising the Training\n",
        "\n",
        "The [`fit(...)` method](https://keras.io/api/models/model_training_apis/#fit-method) returns a `History` object which contains information collected from all epochs.\n",
        "Plotting these data allow us to see how the model performs during the training process. e.g. You should expect the loss to decrease, and accuracy to increase over epoch.\n",
        "If performance worsens with more training, it may indicate that the model is overfitting."
      ],
      "metadata": {
        "id": "jBihw7WIrIgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as pyplot\n",
        "\n",
        "#show keys in the history\n",
        "print(history.history.keys())\n",
        "\n",
        "#plot graphs\n",
        "pd.DataFrame(history.history).plot(figsize=(15,8))\n",
        "pyplot.grid(True)\n",
        "pyplot.gca().set_ylim(0,1)\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "NJZq15EFxS25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing the Model\n",
        "\n",
        "To evaluate the performance of our model, we use the testing dataset.\n",
        "\n",
        "1. Reference of `evaluate()` method is [here](https://keras.io/api/models/model_training_apis/#evaluate-method)."
      ],
      "metadata": {
        "id": "hINWcFxqY9qQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model using the testing dataset\n",
        "(loss,accuracy)=model.evaluate(x_test,y_test)\n",
        "\n",
        "print('Loss: ',loss)\n",
        "print('Accuracy: ',round(accuracy,2)*100,'%')"
      ],
      "metadata": {
        "id": "o1UwUuYmyyjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Doing Prediction\n",
        "\n",
        "We can now use the trained model for prediction. We will:\n",
        "1. Take 1 image from the testing data.\n",
        "1. Ask the trained model to predict which class the image belongs to."
      ],
      "metadata": {
        "id": "LFmZ1ALBrOA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#class names in an array\n",
        "class_names=['T-shirt/top','Trouser','Pullover','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
        "\n",
        "#get a random image from the testing dataset\n",
        "(instance_count,width,height)=x_test.shape    #get dataset size\n",
        "index=random.randint(0,instance_count-1)      #get an index witin dataset\n",
        "image=x_test[index]                           #get image\n",
        "pyplot.imshow(image,cmap='gray')              #show image\n",
        "\n",
        "#need to add 1 dimension to array to fit input shape\n",
        "oneImage=np.expand_dims(image,axis=0)\n",
        "print('Image shape: ',oneImage.shape)\n",
        "\n",
        "#predict image class\n",
        "[prediction]=model.predict(oneImage)\n",
        "print('Prediction output: ',prediction)\n",
        "\n",
        "classIndex=np.argmax(prediction,axis=-1)\n",
        "\n",
        "predictedClass=class_names[classIndex]\n",
        "print('Predicted class: ',predictedClass)\n",
        "print('Known class: ',class_names[y_test[index]])"
      ],
      "metadata": {
        "id": "r-oowJ0HygXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images=x_test[:100]\n",
        "print(images.shape)\n",
        "print(model.predict(images))"
      ],
      "metadata": {
        "id": "wUFr2pRaVAmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tasks\n",
        "You may want to try the followings to see if it can improve the overall performance of your neural network:\n",
        "1. Increase the number of hidden layers.\n",
        "1. Increase the number of neurons in different layers.\n",
        "1. Modify some parameters. e.g. use a different optimizer, learning rate, etc.\n"
      ],
      "metadata": {
        "id": "Q6FPsJFGUrhJ"
      }
    }
  ]
}