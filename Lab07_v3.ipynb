{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgukhui/cm4709/blob/main/Lab07_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CM4709 Computer Vision\n",
        "#Lab 07 Image Segmentation\n",
        "\n",
        "##Aims\n",
        "* Use PointRend to perform image segmentation.\n",
        "* Use YOLO V8 to pefrom image segmentation.\n",
        "\n",
        "Note: The original lab used [Mask RCNN](https://github.com/matterport/Mask_RCNN).\n",
        "However, as software have evolved, the current library versions do not seem to work with Mask RCNN and the older version of Tensorflow is not available in Colab anymore.\n",
        "As a result, we changed to use [PointRend](https://arxiv.org/abs/1912.08193). The whole idea is to illustrate how to do image segmentation using in an\n",
        "existing library. This does not change in using a different network architecture.\n",
        "\n",
        "This lab is based on the code given by [PixelLib](https://github.com/ayoolaolafenwa/PixelLib)."
      ],
      "metadata": {
        "id": "9nISn72KOU74"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mounting GoogleDrive to Colab Runtime\n",
        "\n",
        "As usual, you will need some testing images. It is faster to upload them to GoogleDrive and then mount it to your Colab runtime.\n",
        "\n",
        "In the following code, I use the path `/content/drive` as the mounting point as Colab also has a convenient button mounting to this path."
      ],
      "metadata": {
        "id": "O0u_qhk4PGtQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfaHOhboI6sh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing Images\n",
        "\n",
        "You are advised to organise your files in GoogleDrive. e.g. Create a `Lab07` folder in GoogleDrive to store the notebook file of Lab 07, and a `Lab07/data` folder for the images.\n",
        "\n",
        "1. Download the testing images in Moodle. Optionally, use your own testing images.\n",
        "1. Upload testing images to your GoogleDrive space.\n",
        "\n",
        "The following code shows a testing image using OpenCV.\n",
        "* Note: Modify the filename and image path accordingly.\n"
      ],
      "metadata": {
        "id": "oJHz3w89Qy32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#image filename and path\n",
        "#\n",
        "filename='test.jpg'\n",
        "imagePath='/content/drive/MyDrive/cm4709/Lab07/data'\n",
        "imageFile=imagePath+'/'+filename\n",
        "\n",
        "#show image\n",
        "#\n",
        "img=cv.imread(imageFile)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "euSaL_1Xy58B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Install PixelLib\n",
        "\n",
        "[PixelLib](https://github.com/ayoolaolafenwa/PixelLib) provides some handy libraries to do image segmentation. The current version has updated to used Pytorch instead of Tensorflow.\n",
        "\n",
        "The following shell commands install Pixellib:\n"
      ],
      "metadata": {
        "id": "u6SiNOE3h0BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pixellib"
      ],
      "metadata": {
        "id": "RRnQeeh9Fyka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Pre-trained Model/Weights File\n",
        "\n",
        "Next, we need the pre-trained model's weights.\n",
        "\n",
        "\n",
        "The following shell command downloads the weights file into the default folder of your Colab runtime:"
      ],
      "metadata": {
        "id": "2QVFe9xjjBBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ayoolaolafenwa/PixelLib/releases/download/0.2.0/pointrend_resnet50.pkl"
      ],
      "metadata": {
        "id": "gIb7XUhPO9ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating the Model\n",
        "\n",
        "You are now ready to create a PointRend model to do image segmentation.\n",
        "In the following code:\n",
        "* Modify the path the image if needed.\n",
        "* Modify the path to the weights file if needed.\n",
        "* The function `segmentImage(...)` takes a parameter `output_image_name`. The image segmentation output will be written to this file. Modify this if you need to."
      ],
      "metadata": {
        "id": "i2nq3yBtqc3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pixellib\n",
        "from pixellib.torchbackend.instance import instanceSegmentation\n",
        "\n",
        "#\n",
        "#path to input image\n",
        "#\n",
        "filename='test.jpg'\n",
        "imagePath='/content/drive/MyDrive/cm4709/Lab07/data'\n",
        "imageFile=imagePath+'/'+filename\n",
        "\n",
        "#\n",
        "#path to output result\n",
        "#\n",
        "output='output.jpg'\n",
        "outputPath='/content'\n",
        "outputFile=outputPath+'/'+output\n",
        "\n",
        "segment_image = instanceSegmentation()\n",
        "segment_image.load_model(\"pointrend_resnet50.pkl\")\n",
        "segment_image.segmentImage(imageFile, output_image_name=outputFile)"
      ],
      "metadata": {
        "id": "LlnfQdjIF9fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Seeing the Segmentation Result\n",
        "\n",
        "PointRend saves the result to the image file you specified.\n",
        "Alternatively, the following code displays the output image:"
      ],
      "metadata": {
        "id": "SdHEvjNG1nm2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r1QWBlxDe0S"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#\n",
        "#path to output result\n",
        "#\n",
        "output='output.jpg'\n",
        "outputPath='/content'\n",
        "outputFile=outputPath+'/'+output\n",
        "\n",
        "#\n",
        "#show segementation result\n",
        "#\n",
        "img=cv.imread(outputFile)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Other Functions\n",
        "\n",
        "[PixelLib](https://pixellib.readthedocs.io/en/latest/) has many handy functions built-in.\n",
        "You can see the documentation [here](https://pixellib.readthedocs.io/en/latest/Image_instance.html).\n",
        "For example, you can show the bounding boxes of the detected segments:\n"
      ],
      "metadata": {
        "id": "6dPYJbO_4BLN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVezptU3EHRx"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import pixellib\n",
        "from pixellib.instance import instance_segmentation\n",
        "\n",
        "#\n",
        "#path to input image\n",
        "#\n",
        "filename='test2.jpg'\n",
        "imagePath='/content/drive/MyDrive/cm4709/Lab07/data'\n",
        "imageFile=imagePath+'/'+filename\n",
        "\n",
        "#\n",
        "#path to output result\n",
        "#\n",
        "output='output.jpg'\n",
        "outputPath='/content'\n",
        "outputFile=outputPath+'/'+output\n",
        "\n",
        "#\n",
        "#path to weights file\n",
        "#\n",
        "weightFile='/content/pointrend_resnet50.pkl'\n",
        "\n",
        "#\n",
        "#perform image segmentation\n",
        "#\n",
        "segment_image = instanceSegmentation()\n",
        "segment_image.load_model(weightFile)\n",
        "segment_image.segmentImage(imageFile,show_bboxes=True, output_image_name=outputFile)\n",
        "\n",
        "#\n",
        "#show segementation result\n",
        "#\n",
        "img=cv.imread(outputFile)\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also extract and save the detected segments:"
      ],
      "metadata": {
        "id": "OhK0HyCa5hm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import pixellib\n",
        "from pixellib.torchbackend.instance import instanceSegmentation\n",
        "\n",
        "#\n",
        "#path to output result\n",
        "#\n",
        "output='output.jpg'\n",
        "outputPath='/content'\n",
        "outputFile=outputPath+'/'+output\n",
        "\n",
        "#\n",
        "#path to weights file\n",
        "#\n",
        "weightFile='/content/pointrend_resnet50.pkl'\n",
        "\n",
        "#\n",
        "#perform image segmentation\n",
        "#extract and save segments\n",
        "#\n",
        "segment_image = instanceSegmentation()\n",
        "#segment_image.load_model(weightFile)\n",
        "segment_image.load_model(\"pointrend_resnet50.pkl\")\n",
        "segment_image.segmentImage(imageFile, output_image_name=outputFile,extract_segmented_objects=True,save_extracted_objects=True)"
      ],
      "metadata": {
        "id": "0rFnBp935m-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracted segments are saved to the home of your Colab runtime with filenames `segmented_object_...`.\n",
        "The following code shows all of them:"
      ],
      "metadata": {
        "id": "f0jY_8736IxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import fnmatch\n",
        "\n",
        "segmentPath='.'\n",
        "pattern='segmented_object_*.jpg'\n",
        "segmentFiles=[]\n",
        "\n",
        "#collect segment files full paths\n",
        "#\n",
        "allFiles=os.listdir(segmentPath)\n",
        "for file in allFiles:\n",
        "  if fnmatch.fnmatch(file,pattern):\n",
        "    segmentFiles.append(segmentPath+'/'+file)\n",
        "\n",
        "total=len(segmentFiles) #no. of files\n",
        "print('No. of files: ',total)\n",
        "\n",
        "colCount=10\n",
        "rowCount=int(total/colCount)+1\n",
        "plt.figure(figsize=(colCount*1.5,rowCount*1.5))\n",
        "i=1\n",
        "\n",
        "for file in segmentFiles:\n",
        "  img=cv.imread(file)\n",
        "  cvtImg=cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "  plt.subplot(rowCount,colCount,i)\n",
        "  plt.imshow(cvtImg)\n",
        "  i=i+1"
      ],
      "metadata": {
        "id": "_u2EV3xG6WjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you need to remove all `segemented_object_*.jpg` files between different runs, the following code will be handy:"
      ],
      "metadata": {
        "id": "7OdVWmKABOr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove all extracted segment files\n",
        "#\n",
        "import os\n",
        "import fnmatch\n",
        "\n",
        "segmentPath='.'\n",
        "pattern='segmented_object_*.jpg'\n",
        "\n",
        "#collect segment files full paths\n",
        "#\n",
        "allFiles=os.listdir(segmentPath)\n",
        "for file in allFiles:\n",
        "  if fnmatch.fnmatch(file,pattern):\n",
        "    os.remove(segmentPath+'/'+file)"
      ],
      "metadata": {
        "id": "lv4L2qazAatg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image Segmentation Using YOLO V8\n",
        "\n",
        "Interesting enough, YOLO V8 now also has the image segmentation function.\n",
        "Program code in this part is mostly from [this web page](https://dev.to/andreygermanov/how-to-implement-instance-segmentation-using-yolov8-neural-network-3if9).\n",
        "\n",
        "To use YOLO for the task, we need to install the Ultalytics library:"
      ],
      "metadata": {
        "id": "_Mv9g-uE3crY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install Ultralytic library\n",
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "id": "W87J2jYd3f-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Perform Image Segmentation Using YOLO V8\n",
        "\n",
        "For image segementation, we will need a different weight file trained for the task.\n",
        "Apart from this, the Python code is very similar to object detection.\n",
        "After calling the [`predict(...)` function](https://docs.ultralytics.com/modes/predict/#inference-arguments), what remains is to process the result."
      ],
      "metadata": {
        "id": "t8jvmd-963QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "#\n",
        "#path to input image\n",
        "#\n",
        "filename='test2.jpg'\n",
        "imagePath='/content/drive/MyDrive/cm4709/Lab07/data'\n",
        "imageFile=imagePath+'/'+filename\n",
        "\n",
        "#\n",
        "#download weights for image segmentation\n",
        "#\n",
        "model = YOLO(\"yolov8m-seg.pt\")      #load weights for image segmentation\n",
        "results = model.predict(imageFile)  #predict on 1 image\n"
      ],
      "metadata": {
        "id": "XLWKhqA23sQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Processing the Masks\n",
        "\n",
        "The prediction [result](https://docs.ultralytics.com/modes/predict/#inference-arguments) contains a number of [masks](https://docs.ultralytics.com/modes/predict/#masks).\n",
        "The following code shows the number of masks detected in the image:"
      ],
      "metadata": {
        "id": "7A705quY7vPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = results[0]                 #take 1st result as we have only 1 image\n",
        "masks=result.masks                  #get masks predicted\n",
        "print('No. of masks: ',len(result))"
      ],
      "metadata": {
        "id": "hbiw6gvz4y0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Showing the Masks as Polygons\n",
        "\n",
        "Each mask contains list of x,y coordinates in floating point numbers.\n",
        "By converting the list of coordinates into integers, we can draw out each mask as a polygon using OpenCV."
      ],
      "metadata": {
        "id": "j0sPqnVCQ1oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "import random\n",
        "\n",
        "#\n",
        "#draw masks as polygons\n",
        "#\n",
        "img=cv.imread(imageFile)\n",
        "for mask in masks:\n",
        "  xy=mask.xy[0].astype(int)   #convert float to int\n",
        "  colour=(random.randint(0,255),random.randint(0,255),random.randint(0,255))  #create a random BGR colour for drawing\n",
        "  cv.polylines(img,[xy],isClosed=True,color=colour,thickness=3)               #draw mask as a polygon\n",
        "\n",
        "#\n",
        "#show image with masks drawn\n",
        "#\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "4hkYY6o65_Gy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CWFk68QbTWoElTOhhhA9jo5aqRFFENG_",
      "authorship_tag": "ABX9TyMbQJU0Kxjn1RE5gkY+7O90",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}